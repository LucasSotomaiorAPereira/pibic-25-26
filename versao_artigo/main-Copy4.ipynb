{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66eec202eab352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:51:59.291523Z",
     "start_time": "2025-09-16T13:51:59.286456Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import itertools\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff7fbd-35cd-4bf4-9064-7542fbe66162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_creator import CreatorDL\n",
    "creator = CreatorDL(seed=42, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108772d1-330c-4ea7-b4fa-a96a9c5c06ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_UNSW = creator.reader(\"NF-UNSW-NB15-v3\")\n",
    "\n",
    "df_train_UNSW, df_test_UNSW, df_val_UNSW = creator.splitter(df_UNSW)\n",
    "\n",
    "train_loader_UNSW, test_loader_UNSW, val_loader_UNSW = creator.balancer(df_train_UNSW, df_test_UNSW, df_val_UNSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fca6f-a878-4ab7-bbef-2d77092947de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_BOT= creator.reader(\"NF-BoT-IoT-v3\")\n",
    "\n",
    "df_train_BOT, df_test_BOT, df_val_BOT = creator.splitter(df_BOT)\n",
    "\n",
    "train_loader_BOT, test_loader_BOT, val_loader_BOT = creator.balancer(df_train_BOT, df_test_BOT, df_val_BOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc484e-aa09-40d0-967f-5ffe2b3c7753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_CIC= creator.reader(\"NF-CICIDS2018-v3\")\n",
    "\n",
    "df_train_CIC, df_test_CIC, df_val_CIC = creator.splitter(df_CIC)\n",
    "\n",
    "train_loader_CIC, test_loader_CIC, val_loader_CIC = creator.balancer(df_train_CIC, df_test_CIC, df_val_CIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457e890-0e00-4842-a0eb-2b9a4bc57e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = [train_loader_UNSW, train_loader_BOT, train_loader_CIC]\n",
    "test_loaders = [test_loader_UNSW, test_loader_BOT, test_loader_CIC]\n",
    "val_loaders = [val_loader_UNSW, val_loader_BOT, val_loader_CIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdd023e2b43ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:18.608856Z",
     "start_time": "2025-09-16T14:23:18.591073Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 32\n",
    "\n",
    "class IDSBranchyNet(nn.Module):\n",
    "    def __init__(self, input_dim=INPUT_DIM, num_classes=2):\n",
    "        super(IDSBranchyNet, self).__init__()\n",
    "        \n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(input_dim * 2, input_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "        self.exit1_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.exit2_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward_exit1(self, x):\n",
    "        features = self.shared_layers(x)\n",
    "        return self.exit1_layers(features)\n",
    "\n",
    "    def forward_exit2(self, x):\n",
    "        features = self.shared_layers(x)\n",
    "        return self.exit2_layers(features)\n",
    "\n",
    "model = IDSBranchyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943446ef-8b5f-4e49-82a7-db448f6dede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259e486-8428-444d-b44b-27b7725707eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_soft_count(logits, thresholds, device, sharpness=50.0):\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    confidence, pred_class = torch.max(probs, dim=1)\n",
    "    \n",
    "    if not isinstance(thresholds, torch.Tensor):\n",
    "        t_tensor = torch.tensor(thresholds, dtype=torch.float32).to(device)\n",
    "    else:\n",
    "        t_tensor = thresholds.to(device)\n",
    "        \n",
    "    selected_thresholds = t_tensor[pred_class]\n",
    "    \n",
    "    soft_decisions = torch.sigmoid(sharpness * (confidence - selected_thresholds))\n",
    "    \n",
    "    return soft_decisions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdbb5806d45549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:19.555965Z",
     "start_time": "2025-09-16T14:23:19.548893Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loaders, val_loaders, epochs, lr, attack_threshold, normal_threshold, desired_exit_ex1, device, patience=15):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.001, patience=7)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    \n",
    "    metrics = [\n",
    "        'loss1_a', 'loss1_b', 'loss1_c', 'loss_ex1_avg',\n",
    "        'loss2_a', 'loss2_b', 'loss2_c', 'loss_ex2_avg',\n",
    "        'total_loss', 'joint_loss', 'ex1_pct', 'ex1_diff'\n",
    "    ]\n",
    "\n",
    "    history = {\n",
    "        'train': {k: [] for k in metrics},\n",
    "        'val': {k: [] for k in metrics}\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    max_train_batches = max(len(l) for l in train_loaders) \n",
    "    train_iter_loaders = [itertools.cycle(l) if len(l) < max_train_batches else l for l in train_loaders]\n",
    "    \n",
    "    max_val_batches = max(len(l) for l in val_loaders)\n",
    "    val_iter_loaders = [itertools.cycle(l) if len(l) < max_val_batches else l for l in val_loaders]\n",
    "\n",
    "    class_thresholds = [normal_threshold, attack_threshold]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        running_metrics = {k: 0.0 for k in metrics}\n",
    "        total_steps = 0\n",
    "\n",
    "        loader_iterators = [iter(l) for l in train_iter_loaders]\n",
    "                \n",
    "        for _ in range(max_train_batches):\n",
    "            try:\n",
    "                batches = [next(it) for it in loader_iterators]\n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            (inputs_a, labels_a) = batches[0]\n",
    "            (inputs_b, labels_b) = batches[1]\n",
    "            (inputs_c, labels_c) = batches[2]\n",
    "            \n",
    "            inputs_a, labels_a = inputs_a.to(device), labels_a.to(device)\n",
    "            inputs_b, labels_b = inputs_b.to(device), labels_b.to(device)\n",
    "            inputs_c, labels_c = inputs_c.to(device), labels_c.to(device)\n",
    "            total_samples = inputs_a.size(0) + inputs_b.size(0) + inputs_c.size(0)\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "            \n",
    "            out_a_1 = model.forward_exit1(inputs_a)\n",
    "            loss_a_1 = criterion(out_a_1, labels_a)\n",
    "            \n",
    "            out_a_2 = model.forward_exit2(inputs_a)\n",
    "            loss_a_2 = criterion(out_a_2, labels_a)\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "\n",
    "            out_b_1 = model.forward_exit1(inputs_b)\n",
    "            loss_b_1 = criterion(out_b_1, labels_b)\n",
    "            \n",
    "            out_b_2 = model.forward_exit2(inputs_b)\n",
    "            loss_b_2 = criterion(out_b_2, labels_b)\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "\n",
    "            out_c_1 = model.forward_exit1(inputs_c)\n",
    "            loss_c_1 = criterion(out_c_1, labels_c)\n",
    "            \n",
    "            out_c_2 = model.forward_exit2(inputs_c)\n",
    "            loss_c_2 = criterion(out_c_2, labels_c)\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "\n",
    "            num_ex1_a = exit_soft_count(out_a_1, class_thresholds, device)\n",
    "            num_ex1_b = exit_soft_count(out_b_1, class_thresholds, device)\n",
    "            num_ex1_c = exit_soft_count(out_c_1, class_thresholds, device)\n",
    "\n",
    "            count_ex1 = num_ex1_a + num_ex1_b + num_ex1_c\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "\n",
    "            loss_ex1_avg = (loss_a_1 + loss_b_1 + loss_c_1) / 3\n",
    "            loss_ex2_avg = (loss_a_2 + loss_b_2 + loss_c_2) / 3\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "            \n",
    "            joint_loss = loss_ex1_avg * 1 + loss_ex2_avg * 1\n",
    "            \n",
    "            ex1_percentage = count_ex1 / total_samples\n",
    "\n",
    "            ex1_diff = abs(desired_exit_ex1 - ex1_percentage)\n",
    "            \n",
    "            total_loss = joint_loss + ex1_diff * 1\n",
    "\n",
    "            # ------------------------------------------------------------------------------------------\n",
    "                        \n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_metrics['loss1_a'] += loss_a_1.item()\n",
    "            running_metrics['loss1_b'] += loss_b_1.item()\n",
    "            running_metrics['loss1_c'] += loss_c_1.item()\n",
    "            running_metrics['loss_ex1_avg'] += loss_ex1_avg.item()\n",
    "            \n",
    "            running_metrics['loss2_a'] += loss_a_2.item()\n",
    "            running_metrics['loss2_b'] += loss_b_2.item()\n",
    "            running_metrics['loss2_c'] += loss_c_2.item()\n",
    "            running_metrics['loss_ex2_avg'] += loss_ex2_avg.item()\n",
    "            \n",
    "            running_metrics['total_loss'] += total_loss.item()\n",
    "            \n",
    "            running_metrics['joint_loss'] += joint_loss.item()\n",
    "            running_metrics['ex1_pct'] += ex1_percentage if isinstance(ex1_percentage, (float, int)) else ex1_percentage.item()\n",
    "            running_metrics['ex1_diff'] += ex1_diff.item() if isinstance(ex1_diff, torch.Tensor) else ex1_diff\n",
    "                        \n",
    "            total_steps += 1\n",
    "\n",
    "        for key in metrics:\n",
    "            history['train'][key].append(running_metrics[key] / total_steps)\n",
    "        \n",
    "        epoch_train_loss = history['train']['total_loss'][-1]\n",
    "        epoch_train_loss1 = history['train']['loss_ex1_avg'][-1]\n",
    "        epoch_train_loss2 = history['train']['loss_ex2_avg'][-1]\n",
    "\n",
    "        model.eval()\n",
    "        running_metrics_val = {k: 0.0 for k in metrics}\n",
    "        total_steps_val = 0\n",
    "        \n",
    "        val_loader_iterators = [iter(l) for l in val_iter_loaders]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_val_batches):\n",
    "                try:\n",
    "                    batches = [next(it) for it in val_loader_iterators]\n",
    "                except StopIteration:\n",
    "                    break\n",
    "\n",
    "                (inputs_a, labels_a) = batches[0]\n",
    "                (inputs_b, labels_b) = batches[1]\n",
    "                (inputs_c, labels_c) = batches[2]\n",
    "                \n",
    "                inputs_a, labels_a = inputs_a.to(device), labels_a.to(device)\n",
    "                inputs_b, labels_b = inputs_b.to(device), labels_b.to(device)\n",
    "                inputs_c, labels_c = inputs_c.to(device), labels_c.to(device)\n",
    "                total_samples = inputs_a.size(0) + inputs_b.size(0) + inputs_c.size(0)\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "                \n",
    "                out_a_1 = model.forward_exit1(inputs_a)\n",
    "                loss_a_1 = criterion(out_a_1, labels_a)\n",
    "                \n",
    "                out_a_2 = model.forward_exit2(inputs_a)\n",
    "                loss_a_2 = criterion(out_a_2, labels_a)\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "                out_b_1 = model.forward_exit1(inputs_b)\n",
    "                loss_b_1 = criterion(out_b_1, labels_b)\n",
    "                \n",
    "                out_b_2 = model.forward_exit2(inputs_b)\n",
    "                loss_b_2 = criterion(out_b_2, labels_b)\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "                out_c_1 = model.forward_exit1(inputs_c)\n",
    "                loss_c_1 = criterion(out_c_1, labels_c)\n",
    "                \n",
    "                out_c_2 = model.forward_exit2(inputs_c)\n",
    "                loss_c_2 = criterion(out_c_2, labels_c)\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "                num_ex1_a = exit_soft_count(out_a_1, class_thresholds, device)\n",
    "                num_ex1_b = exit_soft_count(out_b_1, class_thresholds, device)\n",
    "                num_ex1_c = exit_soft_count(out_c_1, class_thresholds, device)\n",
    "    \n",
    "                count_ex1 = num_ex1_a + num_ex1_b + num_ex1_c\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "                loss_ex1_avg = (loss_a_1 + loss_b_1 + loss_c_1) / 3\n",
    "                loss_ex2_avg = (loss_a_2 + loss_b_2 + loss_c_2) / 3\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "                \n",
    "                joint_loss = loss_ex1_avg * 1 + loss_ex2_avg * 1\n",
    "                \n",
    "                ex1_percentage = count_ex1 / total_samples\n",
    "    \n",
    "                ex1_diff = abs(desired_exit_ex1 - ex1_percentage)\n",
    "                \n",
    "                total_loss = joint_loss + ex1_diff * 1\n",
    "    \n",
    "                # ------------------------------------------------------------------------------------------\n",
    "                                                                                                            \n",
    "                running_metrics_val['loss1_a'] += loss_a_1.item()\n",
    "                running_metrics_val['loss1_b'] += loss_b_1.item()\n",
    "                running_metrics_val['loss1_c'] += loss_c_1.item()\n",
    "                running_metrics_val['loss_ex1_avg'] += loss_ex1_avg.item()\n",
    "                \n",
    "                running_metrics_val['loss2_a'] += loss_a_2.item()\n",
    "                running_metrics_val['loss2_b'] += loss_b_2.item()\n",
    "                running_metrics_val['loss2_c'] += loss_c_2.item()\n",
    "                running_metrics_val['loss_ex2_avg'] += loss_ex2_avg.item()\n",
    "                \n",
    "                running_metrics_val['total_loss'] += total_loss.item()\n",
    "\n",
    "                running_metrics_val['joint_loss'] += joint_loss.item()\n",
    "                running_metrics_val['ex1_pct'] += ex1_percentage if isinstance(ex1_percentage, (float, int)) else ex1_percentage.item()\n",
    "                running_metrics_val['ex1_diff'] += ex1_diff.item() if isinstance(ex1_diff, torch.Tensor) else ex1_diff\n",
    "                \n",
    "                total_steps_val += 1\n",
    "\n",
    "        for key in metrics:\n",
    "            history['val'][key].append(running_metrics_val[key] / total_steps_val)\n",
    "\n",
    "        epoch_val_loss = history['val']['total_loss'][-1]\n",
    "        epoch_val_loss1 = history['val']['loss_ex1_avg'][-1]\n",
    "        epoch_val_loss2 = history['val']['loss_ex2_avg'][-1]\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}] | Train Total Loss: {epoch_train_loss:.4f} | Val Total Loss: {epoch_val_loss:.4f}\\nTrain Loss Exit 1: {epoch_train_loss1:.4f} | Train Loss Exit 2: {epoch_train_loss2:.4f}\\nVal Loss Exit 1: {epoch_val_loss1:.4f} | Val Loss Exit 2: {epoch_val_loss2:.4f}\\n\\n')        \n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping...\")\n",
    "                if best_model_state: model.load_state_dict(best_model_state)\n",
    "                break\n",
    "                \n",
    "        scheduler.step(epoch_val_loss)\n",
    "                \n",
    "    epochs_range = range(1, len(history['train']['total_loss']) + 1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 5, figsize=(45, 7))\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.set_title(\"Exit 1\")\n",
    "    ax.plot(epochs_range, history['train']['loss1_a'], label='Tr A', alpha=0.6)\n",
    "    ax.plot(epochs_range, history['train']['loss1_b'], label='Tr B', alpha=0.6)\n",
    "    ax.plot(epochs_range, history['train']['loss1_c'], label='Tr C', alpha=0.6)\n",
    "    ax.plot(epochs_range, history['train']['loss_ex1_avg'], label='Tr Avg', linewidth=2)\n",
    "    ax.plot(epochs_range, history['val']['loss1_a'], label='Val A', linestyle='--')\n",
    "    ax.plot(epochs_range, history['val']['loss1_b'], label='Val B', linestyle='--')\n",
    "    ax.plot(epochs_range, history['val']['loss1_c'], label='Val C', linestyle='--')\n",
    "    ax.plot(epochs_range, history['val']['loss_ex1_avg'], label='Val Avg', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.set_title(\"Exit 2\")\n",
    "    ax.plot(epochs_range, history['train']['loss2_a'], label='Tr A', alpha=0.6)\n",
    "    ax.plot(epochs_range, history['train']['loss2_b'], label='Tr B', alpha=0.6)\n",
    "    ax.plot(epochs_range, history['train']['loss2_c'], label='Tr C', alpha=0.6)\n",
    "    ax.plot(epochs_range, history['train']['loss_ex2_avg'], label='Tr Avg', linewidth=2)\n",
    "    ax.plot(epochs_range, history['val']['loss2_a'], label='Val A', linestyle='--')\n",
    "    ax.plot(epochs_range, history['val']['loss2_b'], label='Val B', linestyle='--')\n",
    "    ax.plot(epochs_range, history['val']['loss2_c'], label='Val C', linestyle='--')\n",
    "    ax.plot(epochs_range, history['val']['loss_ex2_avg'], label='Val Avg', linestyle='--', linewidth=2)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axs[2]\n",
    "    ax.set_title(\"Global Optimization\")\n",
    "    ax.plot(epochs_range, history['train']['total_loss'], label='Tr Total', color='orange')\n",
    "    ax.plot(epochs_range, history['val']['total_loss'], label='Val Total', color='orange', linestyle='--')\n",
    "    ax.plot(epochs_range, history['train']['joint_loss'], label='Tr Joint', color='blue', alpha=0.7)\n",
    "    ax.plot(epochs_range, history['val']['joint_loss'], label='Val Joint', color='blue', linestyle='--', alpha=0.7)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axs[3]\n",
    "    ax.set_title(\"Exit 1 Rate (Percentage)\")\n",
    "    ax.plot(epochs_range, history['train']['ex1_pct'], label='Tr Rate', color='green')\n",
    "    ax.plot(epochs_range, history['val']['ex1_pct'], label='Val Rate', color='green', linestyle='--')\n",
    "    ax.axhline(y=desired_exit_ex1, color='red', linestyle=':', label='Desired')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Ratio (0-1)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axs[4]\n",
    "    ax.set_title(\"Exit 1 Rate Error (|Desired - Actual|)\")\n",
    "    ax.plot(epochs_range, history['train']['ex1_diff'], label='Tr Diff', color='purple')\n",
    "    ax.plot(epochs_range, history['val']['ex1_diff'], label='Val Diff', color='purple', linestyle='--')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9946bd-0c91-41de-a009-cf1b3e1d7a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:19.574727Z",
     "start_time": "2025-09-16T14:23:19.563129Z"
    }
   },
   "outputs": [],
   "source": [
    "def precompute_outputs(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_probs_exit1 = []\n",
    "    all_probs_exit2 = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for samples, labels in loader:\n",
    "            samples = samples.to(device)\n",
    "            \n",
    "            output1 = model.forward_exit1(samples)\n",
    "            probs1 = F.softmax(output1, dim=1)\n",
    "            \n",
    "            output2 = model.forward_exit2(samples)\n",
    "            probs2 = F.softmax(output2, dim=1)\n",
    "\n",
    "            all_probs_exit1.append(probs1.cpu())\n",
    "            all_probs_exit2.append(probs2.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    probs_exit1 = torch.cat(all_probs_exit1)\n",
    "    probs_exit2 = torch.cat(all_probs_exit2)\n",
    "    targets = torch.cat(all_labels)\n",
    "    \n",
    "    return probs_exit1, probs_exit2, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f96e22-c793-499c-b47d-5d5f573a726b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:19.574727Z",
     "start_time": "2025-09-16T14:23:19.563129Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search_rejection(probs_exit1, probs_exit2, targets):\n",
    "    threshold_values = [round(x * 0.05, 2) for x in range(10, 21)] \n",
    "    \n",
    "    results_rejection = []\n",
    "    results_error = []\n",
    "    results_exit1_rate = []\n",
    "    results_exit2_rate = []\n",
    "    \n",
    "    best_error = float('inf')\n",
    "    best_cm = None\n",
    "    best_params = None\n",
    "    best_exit1 = 0.0\n",
    "    best_exit2 = 0.0\n",
    "    best_rej = 0.0\n",
    "    \n",
    "    confs1, preds1 = torch.max(probs_exit1, dim=1)\n",
    "    confs2, preds2 = torch.max(probs_exit2, dim=1)\n",
    "    total_samples = len(targets)\n",
    "    \n",
    "    print(f\"Starting Grid Search with {len(threshold_values)**4} combinations...\")\n",
    "    \n",
    "    count = 0\n",
    "    for t_atk1, t_norm1, t_atk2, t_norm2 in itertools.product(threshold_values, repeat=4):\n",
    "        \n",
    "        thresh_tensor1 = torch.where(preds1 == 1, t_atk1, t_norm1)\n",
    "        mask_exit1 = confs1 > thresh_tensor1\n",
    "        \n",
    "        thresh_tensor2 = torch.where(preds2 == 1, t_atk2, t_norm2)\n",
    "        mask_exit2 = (~mask_exit1) & (confs2 > thresh_tensor2)\n",
    "        \n",
    "        mask_rejected = (~mask_exit1) & (~mask_exit2)\n",
    "        \n",
    "        cnt_exit1 = mask_exit1.sum().item()\n",
    "        cnt_exit2 = mask_exit2.sum().item()\n",
    "        cnt_rejected = mask_rejected.sum().item()\n",
    "        \n",
    "        rate_exit1 = (cnt_exit1 / total_samples)\n",
    "        rate_exit2 = (cnt_exit2 / total_samples)\n",
    "        rate_rejection = (cnt_rejected / total_samples)\n",
    "        \n",
    "        if cnt_rejected == total_samples:\n",
    "            continue\n",
    "\n",
    "        final_preds = preds2.clone()\n",
    "        final_preds[mask_exit1] = preds1[mask_exit1]\n",
    "        \n",
    "        mask_accepted = ~mask_rejected\n",
    "        y_true_accepted = targets[mask_accepted]\n",
    "        y_pred_accepted = final_preds[mask_accepted]\n",
    "        \n",
    "        current_f1 = f1_score(y_true_accepted.numpy(), y_pred_accepted.numpy(), zero_division=0)\n",
    "        error_rate_f1 = (1 - current_f1)\n",
    "        \n",
    "        results_rejection.append(rate_rejection)\n",
    "        results_error.append(error_rate_f1)\n",
    "        results_exit1_rate.append(rate_exit1)\n",
    "        results_exit2_rate.append(rate_exit2)\n",
    "        \n",
    "        if rate_rejection < 11.0:\n",
    "            if error_rate_f1 < best_error:\n",
    "                best_error = error_rate_f1\n",
    "                best_cm = confusion_matrix(y_true_accepted.numpy(), y_pred_accepted.numpy())\n",
    "                best_params = (t_atk1, t_norm1, t_atk2, t_norm2)\n",
    "                best_exit1 = rate_exit1\n",
    "                best_exit2 = rate_exit2\n",
    "                best_rej = rate_rejection\n",
    "        \n",
    "        count += 1\n",
    "        if count % 5000 == 0:\n",
    "            print(f\"{count} combinations processed...\")\n",
    "\n",
    "    return (results_rejection, results_error, results_exit1_rate, results_exit2_rate, \n",
    "            best_cm, best_params, best_exit1, best_exit2, best_rej, best_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704be32-33e9-4107-92ac-e1e8242d2b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:19.574727Z",
     "start_time": "2025-09-16T14:23:19.563129Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_grid_search(model, loader, device):\n",
    "    probs1, probs2, targets = precompute_outputs(model, loader, device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    (rejection, error, exit1_rates, exit2_rates, \n",
    "     best_cm, best_params, best_exit1, best_exit2, best_rej, best_error) = grid_search_rejection(probs1, probs2, targets)\n",
    "    \n",
    "    print(f\"Grid Search concluído em {time.time() - start_time:.2f} segundos.\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sc = plt.scatter(rejection, error, \n",
    "                     c=exit1_rates,\n",
    "                     cmap='viridis',\n",
    "                     s=10, alpha=0.7)\n",
    "    \n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label('Taxa de Uso da Saída 1 (%)')\n",
    "    \n",
    "    plt.xlabel('Taxa de Rejeição (%)')\n",
    "    plt.ylabel('Erro (1 - F1 Score) (%)')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(0, 20)\n",
    "    plt.ylim(0, 10)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'rejection': rejection,\n",
    "        'error': error,\n",
    "        'exit1_rates': exit1_rates,\n",
    "        'exit2_rates': exit2_rates,\n",
    "        'best_cm': best_cm,\n",
    "        'best_params': best_params,\n",
    "        'best_exit1': best_exit1,\n",
    "        'best_exit2': best_exit2,\n",
    "        'best_rej': best_rej,\n",
    "        'best_error': best_error\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbf4b5-dcc6-4bd5-96e5-b96988ebd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'arq_v2_abor_v3'\n",
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef852c-867f-440f-bb30-d0adec7af30a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:28:08.281274Z",
     "start_time": "2025-09-16T14:23:19.576754Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "\n",
    "history = train_model(\n",
    "    model.to(device), \n",
    "    train_loaders, \n",
    "    val_loaders, \n",
    "    epochs,\n",
    "    lr=0.0001,\n",
    "    attack_threshold=0.85,\n",
    "    normal_threshold=0.85,\n",
    "    desired_exit_ex1=0.4,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), f'models/{modelname}.pth')\n",
    "print(f\"\\nModelo treinado e salvo em 'models/{modelname}.pth'\")\n",
    "\n",
    "df_train = pd.DataFrame(history['train'])\n",
    "df_val = pd.DataFrame(history['val'])\n",
    "\n",
    "df_train = df_train.add_prefix('train_')\n",
    "df_val = df_val.add_prefix('val_')\n",
    "\n",
    "df_history = pd.concat([df_train, df_val], axis=1)\n",
    "\n",
    "df_history.insert(0, 'epoch', range(1, len(df_history) + 1))\n",
    "\n",
    "csv_filename = f'logs/{modelname}_history.csv'\n",
    "df_history.to_csv(csv_filename, index=False)\n",
    "print(f\"Curvas de aprendizado salvas em '{csv_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487a354-427f-4895-9237-1322bc90039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_para_concatenar = [test_loader_UNSW, test_loader_BOT, test_loader_CIC]\n",
    "\n",
    "datasets = [loader.dataset for loader in loaders_para_concatenar]\n",
    "\n",
    "combined_dataset = ConcatDataset(datasets)\n",
    "\n",
    "bs = loaders_para_concatenar[0].batch_size\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=bs, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Total de amostras combinadas: {len(combined_dataset)}\")\n",
    "print(f\"Total de batches: {len(combined_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3937e6b-898b-4693-9cbe-fb0f9ce04fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
