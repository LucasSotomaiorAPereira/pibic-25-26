{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71fa66b-ed62-456d-b77e-584903b176f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2017b941-a25b-4b2f-9204-bf15ab595e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7443699-9939-458c-a176-7ace528be0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_balancer(df, seed):\n",
    "    df_benign = df[df['Attack'] == 'Benign']\n",
    "    df_attacks = df[df['Attack'] != 'Benign']\n",
    "    \n",
    "    rus = df_attacks['Attack'].value_counts().min()\n",
    "    if rus < 1000:\n",
    "        rus = 1000\n",
    "    \n",
    "    df_attacks_balanced = df_attacks.groupby('Attack').sample(n=rus, replace=True, random_state=seed)\n",
    "    \n",
    "    num_attack_classes = len(df_attacks['Attack'].unique())\n",
    "    num_benign_samples = num_attack_classes * rus\n",
    "    df_benign_sampled = df_benign.sample(n=num_benign_samples, random_state=seed)\n",
    "    \n",
    "    df = pd.concat([df_attacks_balanced, df_benign_sampled])\n",
    "    df = shuffle(df, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacc81ce-e04c-4645-af47-1555ee80120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_creator(filename, seed):\n",
    "    print(f\"Processing: {filename}...\")\n",
    "    df = pd.read_csv(f'../db/{filename}.csv') \n",
    "\n",
    "    df.drop(['IPV4_SRC_ADDR',\n",
    "         'IPV4_DST_ADDR',\n",
    "         'L4_SRC_PORT',\n",
    "         'L4_DST_PORT',\n",
    "         'L7_PROTO',\n",
    "         'TCP_FLAGS',\n",
    "         'CLIENT_TCP_FLAGS',\n",
    "         'SERVER_TCP_FLAGS',\n",
    "         'MIN_TTL', \n",
    "         'MAX_TTL',\n",
    "         'SHORTEST_FLOW_PKT',\n",
    "         'MIN_IP_PKT_LEN', \n",
    "         'TCP_WIN_MAX_IN', \n",
    "         'TCP_WIN_MAX_OUT', \n",
    "         'DNS_QUERY_ID', \n",
    "         'DNS_TTL_ANSWER',\n",
    "         'FTP_COMMAND_RET_CODE',\n",
    "         'SRC_TO_DST_SECOND_BYTES',\n",
    "         'DST_TO_SRC_SECOND_BYTES',\n",
    "         'FLOW_START_MILLISECONDS',\n",
    "         'FLOW_END_MILLISECONDS',], inplace=True, axis=1)\n",
    "    \n",
    "    dictionary_sets_by_attack_type = {}\n",
    "    attack_types = df['Attack'].unique()\n",
    "\n",
    "    for attack_type in attack_types:\n",
    "        print(f\"Processando a categoria: '{attack_type}'\")\n",
    "        df_current_attack = df[df['Attack'] == attack_type]\n",
    "    \n",
    "        df_train_current_attack, df_aux_current_attack = train_test_split(df_current_attack, train_size=0.5, random_state=seed)\n",
    "        df_test_current_attack, df_val_current_attack = train_test_split(df_aux_current_attack, train_size=0.5, random_state=seed)\n",
    "    \n",
    "        dictionary_sets_by_attack_type[attack_type] = {\n",
    "            'treino': df_train_current_attack,\n",
    "            'teste': df_test_current_attack,\n",
    "            'validacao': df_val_current_attack\n",
    "        }\n",
    "        print(f\"  -> Treino: {len(df_train_current_attack)} | Teste: {len(df_test_current_attack)} | Validação: {len(df_val_current_attack)}\")\n",
    "\n",
    "\n",
    "    list_train = [dictionary_sets_by_attack_type[attack_type]['treino'] for attack_type in attack_types]\n",
    "    df_train = pd.concat(list_train)\n",
    "    df_train = shuffle(df_train, random_state=seed).reset_index(drop=True)\n",
    "    df_train = dfs_balancer(df_train, seed)\n",
    "    \n",
    "    list_test = [dictionary_sets_by_attack_type[attack_type]['teste'] for attack_type in attack_types]\n",
    "    df_test = pd.concat(list_test)\n",
    "    df_test = shuffle(df_test, random_state=seed).reset_index(drop=True)\n",
    "    df_test = dfs_balancer(df_test, seed)\n",
    "    \n",
    "    list_val = [dictionary_sets_by_attack_type[attack_type]['validacao'] for attack_type in attack_types]\n",
    "    df_val = pd.concat(list_val)\n",
    "    df_val = shuffle(df_val, random_state=seed).reset_index(drop=True)\n",
    "    df_val = dfs_balancer(df_val, seed)\n",
    "\n",
    "    print(f\"--- Base de Treino ---\")\n",
    "    print(f\"Tamanho: {len(df_train)} linhas\")\n",
    "    print(f\"Categorias presentes: {df_train['Attack'].unique()}\")\n",
    "    print(df_train['Attack'].value_counts())\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    print(f\"\\n--- Base de Teste ---\")\n",
    "    print(f\"Tamanho: {len(df_test)} linhas\")\n",
    "    print(f\"Categorias presentes: {df_test['Attack'].unique()}\")\n",
    "    print(df_test['Attack'].value_counts())\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    print(f\"\\n--- Base de Validação ---\")\n",
    "    print(f\"Tamanho: {len(df_val)} linhas\")\n",
    "    print(f\"Categorias presentes: {df_val['Attack'].unique()}\")\n",
    "    print(df_val['Attack'].value_counts())\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    return {\n",
    "        'train': df_train,\n",
    "        'val': df_val,\n",
    "        'test': df_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5648cbef-2afb-4ef0-b269-828902a03f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_creator(df, seed):    \n",
    "    X = df.drop(['Label', 'Attack'], axis=1)\n",
    "    y = df['Label'].to_numpy()\n",
    "    \n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa38b65-99ce-451a-afdd-c571c8775060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_creator(X, y, bs, train=False):\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "if train == True\n",
    "    loader = DataLoader(ataset, batch_size=bs, shuffle=True, num_workers=88)\n",
    "else:\n",
    "    loader = DataLoader(ataset, batch_size=bs, shuffle=False, num_workers=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb1c3c-9ee4-4844-8450-693e5aaefe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "Xs = {}\n",
    "ys = {}\n",
    "dataloaders = {}\n",
    "filenames = ['NF-UNSW-NB15-v3', 'NF-BoT-IoT-v3', 'NF-CICIDS2018-v3']\n",
    "\n",
    "for f in filenames:\n",
    "    datasets[f] = dfs_creator(f, SEED)\n",
    "\n",
    "for dataset in datasets:\n",
    "    auxX = {}\n",
    "    auxy = {}\n",
    "    for i in dataset:\n",
    "        x, y = Xy_creator(i, SEED)\n",
    "        auxX[i] = x\n",
    "        auxy[i] = y\n",
    "    Xs[dataset] = auxX\n",
    "    ys[dataset] = auxy\n",
    "\n",
    "for x, y in zip(Xs, ys):\n",
    "    dataloaders[f] = dataloaders_creator(X[f], y[f], BATCH_SIZE, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
