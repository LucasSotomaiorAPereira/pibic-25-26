{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66eec202eab352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:51:59.291523Z",
     "start_time": "2025-09-16T13:51:59.286456Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083fc1de-a5f0-40ef-95ad-6292a7bcea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_creator import CreatorDL\n",
    "creator = CreatorDL(seed=42, bs=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fea3de-560c-4588-a713-b5ee38ddff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UNSW = creator.reader(\"NF-UNSW-NB15-v3\")\n",
    "\n",
    "df_train_UNSW, df_test_UNSW, df_val_UNSW = creator.splitter(df_UNSW)\n",
    "\n",
    "train_loader_UNSW, test_loader_UNSW, val_loader_UNSW = creator.balancer(df_train_UNSW, df_test_UNSW, df_val_UNSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208270d-abd1-404c-854d-611790d07704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BOT= creator.reader(\"NF-BoT-IoT-v3\")\n",
    "\n",
    "df_train_BOT, df_test_BOT, df_val_BOT = creator.splitter(df_BOT)\n",
    "\n",
    "train_loader_BOT, test_loader_BOT, val_loader_BOT = creator.balancer(df_train_BOT, df_test_BOT, df_val_BOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62984a55-23e4-4690-8d55-7ed2dae6f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CIC= creator.reader(\"NF-CICIDS2018-v3\")\n",
    "\n",
    "df_train_CIC, df_test_CIC, df_val_CIC = creator.splitter(df_CIC)\n",
    "\n",
    "train_loader_CIC, test_loader_CIC, val_loader_CIC = creator.balancer(df_train_CIC, df_test_CIC, df_val_CIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aeb779-39c4-44a3-a2a1-cf4576712032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = [train_loader_UNSW, train_loader_BOT, train_loader_CIC]\n",
    "test_loaders = [test_loader_UNSW, test_loader_BOT, test_loader_CIC]\n",
    "val_loaders = [val_loader_UNSW, val_loader_BOT, val_loader_CIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931bd0c8c313863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:51:59.285447Z",
     "start_time": "2025-09-16T13:51:50.364805Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_dfs = [df_UNSW, df_BOT, df_CIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b9109-26ea-4e79-a859-107a5d9a2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Concatenando os dataframes...\")\n",
    "df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "df_val = shuffle(df, random_state=42).reset_index(drop=True)\n",
    "print(f\"Processo finalizado! O dataframe final contém {len(df)} linhas.\")\n",
    "df_val.to_csv('db/concat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdd023e2b43ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:18.608856Z",
     "start_time": "2025-09-16T14:23:18.591073Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES = X_train.shape[1]\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "class IDSBranchyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IDSBranchyNet, self).__init__()\n",
    "        self.main_part1 = nn.Sequential(\n",
    "            nn.Linear(NUM_FEATURES, 82),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.main_part2 = nn.Sequential(\n",
    "            nn.Linear(82, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, NUM_CLASSES)\n",
    "        )\n",
    "        self.branch = nn.Sequential(\n",
    "            nn.Linear(82, 41),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(41, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, part=\"both\", intermediate_output=None):\n",
    "        if part == \"branch\":\n",
    "            intermediate_output = self.main_part1(x)\n",
    "            branch_output = self.branch(intermediate_output)\n",
    "            return branch_output, intermediate_output\n",
    "\n",
    "        if part == \"main\":\n",
    "            main_output = self.main_part2(intermediate_output)\n",
    "            return main_output\n",
    "        \n",
    "        if part == \"both\":\n",
    "            intermediate_output = self.main_part1(x)\n",
    "            branch_output = self.branch(intermediate_output)\n",
    "            main_output = self.main_part2(intermediate_output)\n",
    "            return [branch_output, main_output]\n",
    "\n",
    "model = IDSBranchyNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23ebb7-f861-47d4-a731-ed1a3201e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IDSBranchyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdbb5806d45549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:19.555965Z",
     "start_time": "2025-09-16T14:23:19.548893Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, weight_branch, weight_main, lr, device, patience=15):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, \"both\")\n",
    "            loss_branch = criterion(outputs[0], labels)\n",
    "            loss_main = criterion(outputs[1], labels)\n",
    "\n",
    "            total_loss = (weight_branch * loss_branch) + (weight_main * loss_main)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += total_loss.item()\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs, \"both\")\n",
    "                loss_branch = criterion(outputs[0], labels)\n",
    "                loss_main = criterion(outputs[1], labels)\n",
    "                \n",
    "                total_loss = (weight_branch * loss_branch) + (weight_main * loss_main)\n",
    "                val_loss += total_loss.item()\n",
    "        \n",
    "        epoch_val_loss = val_loss/len(val_loader)\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}')\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'\\n--- EARLY STOPPING ATIVADO ---')\n",
    "            print(f'Parando o treino na época {epoch+1} pois a loss de validação não melhora há {patience} épocas.')\n",
    "            print(f'A melhor loss de validação foi: {best_val_loss:.4f}')\n",
    "            if best_model_state:\n",
    "                model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_loss_history) + 1), train_loss_history, label='Loss de Treinamento')\n",
    "    plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, label='Loss de Validação')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Curvas de Loss de Treinamento e Validação')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9acd9be6862e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:23:19.574727Z",
     "start_time": "2025-09-16T14:23:19.563129Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, confidence_threshold, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_samples = len(loader.dataset)\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    exited_early_count = 0\n",
    "    total_inference_time = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for samples, labels in loader:\n",
    "            samples, labels = samples.to(device), labels.to(device)\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            branch_output, intermediate_output = model(samples, \"branch\")\n",
    "            branch_prob = F.softmax(branch_output, dim=1)\n",
    "            trusts, branch_preds = torch.max(branch_prob, 1)\n",
    "\n",
    "            batch_predictions = torch.zeros_like(labels)\n",
    "            \n",
    "            early_exit_mask = trusts > confidence_threshold\n",
    "            \n",
    "            if early_exit_mask.any():\n",
    "                batch_predictions[early_exit_mask] = branch_preds[early_exit_mask]\n",
    "                exited_early_count += early_exit_mask.sum().item()\n",
    "\n",
    "            main_branch_mask = ~early_exit_mask\n",
    "            if main_branch_mask.any():\n",
    "                intermediate_to_main = intermediate_output[main_branch_mask]\n",
    "                \n",
    "                main_output = model(None, \"main\", intermediate_to_main)\n",
    "                main_prob = F.softmax(main_output, dim=1)\n",
    "                _, main_preds = torch.max(main_prob, 1)\n",
    "                \n",
    "                batch_predictions[main_branch_mask] = main_preds\n",
    "\n",
    "            end_time = time.perf_counter()\n",
    "            total_inference_time += (end_time - start_time)\n",
    "\n",
    "            all_predictions.append(batch_predictions.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    final_predictions = torch.cat(all_predictions)\n",
    "    y_data = torch.cat(all_labels)\n",
    "\n",
    "    correct = (final_predictions == y_data).sum().item()\n",
    "    accuracy = 100 * correct / total_samples\n",
    "    exit_rate = 100 * exited_early_count / total_samples\n",
    "    avg_time_ms = (total_inference_time / total_samples) * 1000\n",
    "\n",
    "    cm = confusion_matrix(y_data.numpy(), final_predictions.numpy())\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Normal', 'Ataque'],\n",
    "                yticklabels=['Normal', 'Ataque'])\n",
    "    plt.xlabel('Rótulo Previsto')\n",
    "    plt.ylabel('Rótulo Verdadeiro')\n",
    "    plt.title(f'Matriz de Confusão (Limiar de Confiança = {confidence_threshold})')\n",
    "    plt.show()\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    f1 = f1_score(y_data.numpy(), final_predictions.numpy())\n",
    "    \n",
    "    tpr = recall_score(y_data.numpy(), final_predictions.numpy())\n",
    "\n",
    "    tnr = tn / (tn + fp)\n",
    "    \n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\\n\")\n",
    "    \n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"True Positive Rate (TPR) / Recall: {tpr:.4f}\")\n",
    "    print(f\"True Negative Rate (TNR) / Specificity: {tnr:.4f}\")\n",
    "\n",
    "    return {\n",
    "            'accuracy': accuracy,\n",
    "            'exit_rate': exit_rate,\n",
    "            'avg_inference_time_ms': avg_time_ms,\n",
    "            'exited_early_count': exited_early_count,\n",
    "            'total_samples': total_samples\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbf4b5-dcc6-4bd5-96e5-b96988ebd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'AMBOS'\n",
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa503de6-0891-480d-91f1-7f590d1364f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_id = 4\n",
    "teste_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef852c-867f-440f-bb30-d0adec7af30a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:28:08.281274Z",
     "start_time": "2025-09-16T14:23:19.576754Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, epochs, weight_branch=0, weight_main=1, lr=0.00001, device=device)\n",
    "\n",
    "torch.save(model.state_dict(), f'models/09-11/teste{teste_id}/{modelname}.pth')\n",
    "print(f\"\\nModelo treinado e salvo em 'models/09-11/teste{teste_id}/{modelname}.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248ef82-7a24-4504-8cbc-ae2e4e3422fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T14:28:08.281274Z",
     "start_time": "2025-09-16T14:23:19.576754Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Evaluation on Test Set using DataLoader ---\")\n",
    "\n",
    "model.load_state_dict(torch.load(f'models/09-11/teste{teste_id}/{modelname}.pth'))\n",
    "print(f\"Modelo 'models/09-11/teste{teste_id}/{modelname}.pth' carregado\")\n",
    "\n",
    "\n",
    "thresholds_to_test = [0.8]\n",
    "\n",
    "for T in thresholds_to_test:\n",
    "    results = evaluate_model(model, test_loader, confidence_threshold=T, device=device)\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Threshold: {T}\")\n",
    "    print(f\"  Accuracy: {results['accuracy']:.2f}%\")\n",
    "    print(f\"  Avg. Inference Time: {results['avg_inference_time_ms']:.4f} ms\")\n",
    "    print(f\"  Early Exit Rate: {results['exit_rate']:.2f}% ({results['exited_early_count']}/{results['total_samples']})\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d1f61-6752-4720-bddb-8f1ab58f5141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
